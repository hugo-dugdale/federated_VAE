{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Federated Variational Autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'ELECTRON_RUN_AS_NODE': '1', 'GJS_DEBUG_TOPICS': 'JS ERROR;JS LOG', 'LESSOPEN': '| /usr/bin/lesspipe %s', 'CONDA_PROMPT_MODIFIER': '(base) ', 'LANGUAGE': 'en_GB:en', 'USER': 'ic-ai4health-fri', 'SSH_AGENT_PID': '3686', 'XDG_SESSION_TYPE': 'x11', 'SHLVL': '1', 'HOME': '/home/ic-ai4health-fri', 'CONDA_SHLVL': '1', 'OLDPWD': '/home/ic-ai4health-fri/Projects/DL_CW_1_hd119', 'DESKTOP_SESSION': 'ubuntu', 'GNOME_SHELL_SESSION_MODE': 'ubuntu', 'GTK_MODULES': 'gail:atk-bridge', 'MANAGERPID': '3479', 'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1000/bus', 'COLORTERM': 'truecolor', '_CE_M': '', 'IM_CONFIG_PHASE': '1', 'LOGNAME': 'ic-ai4health-fri', 'JOURNAL_STREAM': '8:190685', '_': '/usr/bin/code', 'XDG_SESSION_CLASS': 'user', 'USERNAME': 'ic-ai4health-fri', 'TERM': 'xterm-color', 'GNOME_DESKTOP_SESSION_ID': 'this-is-deprecated', '_CE_CONDA': '', 'WINDOWPATH': '2', 'PATH': '/home/ic-ai4health-fri/miniconda3/envs/pytorch/bin:/home/ic-ai4health-fri/miniconda3/bin:/home/ic-ai4health-fri/miniconda3/condabin:/home/ic-ai4health-fri/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ic-ai4health-fri/miniconda3/bin:/home/ic-ai4health-fri/miniconda3/condabin:/home/ic-ai4health-fri/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin', 'SESSION_MANAGER': 'local/icai4healthfri-System-Product-Name:@/tmp/.ICE-unix/3721,unix/icai4healthfri-System-Product-Name:/tmp/.ICE-unix/3721', 'INVOCATION_ID': '64ba6f0d399a4f558168b67251468737', 'XDG_MENU_PREFIX': 'gnome-', 'GNOME_TERMINAL_SCREEN': '/org/gnome/Terminal/screen/db8c8c6d_2764_463f_ac2b_71f8b395ef84', 'XDG_RUNTIME_DIR': '/run/user/1000', 'DISPLAY': ':1', 'LANG': 'en_GB.UTF-8', 'XDG_CURRENT_DESKTOP': 'Unity', 'XMODIFIERS': '@im=ibus', 'XDG_SESSION_DESKTOP': 'ubuntu', 'XAUTHORITY': '/run/user/1000/gdm/Xauthority', 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:', 'GNOME_TERMINAL_SERVICE': ':1.4217', 'SSH_AUTH_SOCK': '/run/user/1000/keyring/ssh', 'CONDA_PYTHON_EXE': '/home/ic-ai4health-fri/miniconda3/bin/python', 'SHELL': '/bin/bash', 'QT_ACCESSIBILITY': '1', 'GDMSESSION': 'ubuntu', 'LESSCLOSE': '/usr/bin/lesspipe %s %s', 'CONDA_DEFAULT_ENV': 'base', 'GPG_AGENT_INFO': '/run/user/1000/gnupg/S.gpg-agent:0:1', 'GJS_DEBUG_OUTPUT': 'stderr', 'QT_IM_MODULE': 'ibus', 'PWD': '/home/ic-ai4health-fri/Projects/federated_autoencoder', 'XDG_CONFIG_DIRS': '/etc/xdg/xdg-ubuntu:/etc/xdg', 'CONDA_EXE': '/home/ic-ai4health-fri/miniconda3/bin/conda', 'XDG_DATA_DIRS': '/usr/share/ubuntu:/usr/local/share/:/usr/share/:/var/lib/snapd/desktop', 'CONDA_PREFIX': '/home/ic-ai4health-fri/miniconda3', 'VTE_VERSION': '6003', 'VSCODE_CWD': '/home/ic-ai4health-fri/Projects/federated_autoencoder', 'VSCODE_CLI': '1', 'ELECTRON_NO_ATTACH_CONSOLE': '1', 'CHROME_DESKTOP': 'code-url-handler.desktop', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'ubuntu:GNOME', 'GDK_BACKEND': 'x11', 'VSCODE_NLS_CONFIG': '{\"locale\":\"en-gb\",\"availableLanguages\":{},\"_languagePackSupport\":true}', 'VSCODE_CODE_CACHE_PATH': '/home/ic-ai4health-fri/.config/Code/CachedData/97dec172d3256f8ca4bfb2143f3f76b503ca0534', 'VSCODE_IPC_HOOK': '/run/user/1000/vscode-70b797d3-1.74.3-main.sock', 'VSCODE_PID': '385358', 'NO_AT_BRIDGE': '1', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'utf-8', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline'})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **i. Imports and subfunctions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ic-ai4health-fri/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/ic-ai4health-fri/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from mcvae.models import Mcvae, ThreeLayersVAE, VAE\n",
    "\n",
    "# Subfunctions\n",
    "def split_iid(dataset, n_centers):\n",
    "    \"\"\"\n",
    "    Split PyTorch dataset randomly into n_centers.\n",
    "    \"\"\"\n",
    "    n_obs_per_center = [len(dataset) // n_centers for _ in range(n_centers)]\n",
    "    return random_split(dataset, n_obs_per_center)\n",
    "\n",
    "def federated_averaging(models, n_obs_per_client):\n",
    "    \"\"\"\n",
    "    Perform federated averaging.\n",
    "    \"\"\"\n",
    "    # Error check inputs\n",
    "    assert len(models) > 0\n",
    "    assert len(n_obs_per_client) == len(models)\n",
    "\n",
    "    # Compute proportions\n",
    "    n_obs = sum(n_obs_per_client)\n",
    "    proportions = [n_k / n_obs for n_k in n_obs_per_client]\n",
    "\n",
    "    # Empty model parameter dictionary\n",
    "    avg_params = models[0].state_dict()\n",
    "    for key, val in avg_params.items():\n",
    "        avg_params[key] = torch.zeros_like(val)\n",
    "\n",
    "    # Compute average\n",
    "    for model, proportion in zip(models, proportions):\n",
    "        for key in avg_params.keys():\n",
    "            avg_params[key] += proportion * model.state_dict()[key]\n",
    "\n",
    "    # Copy one of the models and load trained params\n",
    "    avg_model = copy.deepcopy(models[0])\n",
    "    avg_model.load_state_dict(avg_params)\n",
    "\n",
    "    return avg_model\n",
    "\n",
    "def get_data(subset, shuffle=True):\n",
    "    \"\"\"\n",
    "    Extracts data from a Subset torch dataset in the form of a tensor.\n",
    "    \"\"\"\n",
    "    loader = DataLoader(subset, batch_size=len(subset), shuffle=shuffle)\n",
    "    return next(iter(loader)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ii. General setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define federated parameters\n",
    "N_CENTERS = 4\n",
    "N_ROUNDS = 10\n",
    "\n",
    "# Define learning parameters\n",
    "N_EPOCHS = 15\n",
    "BATCH_SIZE = 48\n",
    "LR = 1e-3\n",
    "\n",
    "# # Define GPU\n",
    "# USE_GPU = True\n",
    "# dtype = torch.float32 \n",
    "# if USE_GPU and torch.cuda.is_available():\n",
    "#     device = torch.device('cuda:0')\n",
    "# else:\n",
    "#     device = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of centers: 4\n"
     ]
    }
   ],
   "source": [
    "# Define data transforms and download\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0,), (1,))])\n",
    "dataset = datasets.MNIST('~/data/', train=True, download=True, transform=transform)\n",
    "\n",
    "# Federate data\n",
    "federated_dataset = split_iid(dataset, n_centers=N_CENTERS)\n",
    "print('Number of centers:', len(federated_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Create model and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature dimensions and dummy data\n",
    "N_FEATURES = 784\n",
    "dummy_data = [torch.zeros(1, N_FEATURES)]\n",
    "\n",
    "# Model architecture\n",
    "lat_dim = 3\n",
    "vae_class = ThreeLayersVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE models\n",
    "model = Mcvae(data=dummy_data, lat_dim=lat_dim, vaeclass=vae_class)\n",
    "model.optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "model.init_loss()\n",
    "# model = model.to(device=device)\n",
    "models = [copy.deepcopy(model) for _ in range(N_CENTERS)]\n",
    "n_obs_per_client = [len(client_data) for client_data in federated_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch:    0/15 (0%)\tLoss: 542.5519\tLL: -542.5479\tKL: 0.0041\tLL/KL: -133920.3389\n",
      "====> Epoch:   10/15 (67%)\tLoss: 74.6212\tLL: -70.1510\tKL: 4.4702\tLL/KL: -15.6930\n",
      "====> Epoch:    0/15 (0%)\tLoss: 548.2899\tLL: -548.2858\tKL: 0.0040\tLL/KL: -135640.7928\n",
      "====> Epoch:   10/15 (67%)\tLoss: 76.3847\tLL: -71.9886\tKL: 4.3960\tLL/KL: -16.3758\n",
      "====> Epoch:    0/15 (0%)\tLoss: 541.0313\tLL: -541.0273\tKL: 0.0041\tLL/KL: -133540.9558\n",
      "====> Epoch:   10/15 (67%)\tLoss: 73.7192\tLL: -69.3528\tKL: 4.3664\tLL/KL: -15.8833\n",
      "====> Epoch:    0/15 (0%)\tLoss: 545.7291\tLL: -545.7250\tKL: 0.0041\tLL/KL: -133587.2160\n",
      "====> Epoch:   10/15 (67%)\tLoss: 76.5488\tLL: -72.1437\tKL: 4.4051\tLL/KL: -16.3773\n",
      "====> Epoch:   20/30 (67%)\tLoss: 45.8481\tLL: -33.8719\tKL: 11.9762\tLL/KL: -2.8283\n",
      "====> Epoch:   20/30 (67%)\tLoss: 47.9345\tLL: -35.9531\tKL: 11.9814\tLL/KL: -3.0007\n",
      "====> Epoch:   20/30 (67%)\tLoss: 45.4779\tLL: -33.4726\tKL: 12.0053\tLL/KL: -2.7882\n",
      "====> Epoch:   20/30 (67%)\tLoss: 48.0424\tLL: -36.1164\tKL: 11.9260\tLL/KL: -3.0284\n",
      "====> Epoch:   30/45 (67%)\tLoss: 6.1330\tLL: 0.2990\tKL: 6.4320\tLL/KL: 0.0465\n",
      "====> Epoch:   40/45 (89%)\tLoss: -17.9907\tLL: 25.9131\tKL: 7.9224\tLL/KL: 3.2709\n",
      "====> Epoch:   30/45 (67%)\tLoss: 8.7127\tLL: -2.2549\tKL: 6.4578\tLL/KL: -0.3492\n",
      "====> Epoch:   40/45 (89%)\tLoss: -15.0970\tLL: 23.0034\tKL: 7.9064\tLL/KL: 2.9095\n",
      "====> Epoch:   30/45 (67%)\tLoss: 5.6198\tLL: 0.7928\tKL: 6.4126\tLL/KL: 0.1236\n",
      "====> Epoch:   40/45 (89%)\tLoss: -18.3229\tLL: 26.2541\tKL: 7.9312\tLL/KL: 3.3102\n",
      "====> Epoch:   30/45 (67%)\tLoss: 8.6012\tLL: -2.1580\tKL: 6.4432\tLL/KL: -0.3349\n",
      "====> Epoch:   40/45 (89%)\tLoss: -15.4475\tLL: 23.3364\tKL: 7.8889\tLL/KL: 2.9581\n",
      "====> Epoch:   50/60 (83%)\tLoss: -44.9532\tLL: 53.9238\tKL: 8.9707\tLL/KL: 6.0111\n",
      "====> Epoch:   50/60 (83%)\tLoss: -41.4980\tLL: 50.5464\tKL: 9.0483\tLL/KL: 5.5863\n",
      "====> Epoch:   50/60 (83%)\tLoss: -44.6326\tLL: 53.5664\tKL: 8.9338\tLL/KL: 5.9960\n",
      "====> Epoch:   50/60 (83%)\tLoss: -42.7542\tLL: 51.7528\tKL: 8.9987\tLL/KL: 5.7512\n",
      "====> Epoch:   60/75 (80%)\tLoss: -64.1565\tLL: 72.4925\tKL: 8.3360\tLL/KL: 8.6964\n",
      "====> Epoch:   70/75 (93%)\tLoss: -78.8302\tLL: 87.8559\tKL: 9.0256\tLL/KL: 9.7340\n",
      "====> Epoch:   60/75 (80%)\tLoss: -60.9838\tLL: 69.3603\tKL: 8.3765\tLL/KL: 8.2803\n",
      "====> Epoch:   70/75 (93%)\tLoss: -75.5491\tLL: 84.5610\tKL: 9.0119\tLL/KL: 9.3833\n",
      "====> Epoch:   60/75 (80%)\tLoss: -64.9134\tLL: 73.2407\tKL: 8.3273\tLL/KL: 8.7953\n",
      "====> Epoch:   70/75 (93%)\tLoss: -79.6248\tLL: 88.6603\tKL: 9.0355\tLL/KL: 9.8124\n",
      "====> Epoch:   60/75 (80%)\tLoss: -61.8981\tLL: 70.2561\tKL: 8.3580\tLL/KL: 8.4058\n",
      "====> Epoch:   70/75 (93%)\tLoss: -77.3301\tLL: 86.2776\tKL: 8.9475\tLL/KL: 9.6426\n",
      "====> Epoch:   80/90 (89%)\tLoss: -92.2069\tLL: 100.9280\tKL: 8.7211\tLL/KL: 11.5729\n",
      "====> Epoch:   80/90 (89%)\tLoss: -89.3643\tLL: 98.0818\tKL: 8.7176\tLL/KL: 11.2510\n",
      "====> Epoch:   80/90 (89%)\tLoss: -93.7348\tLL: 102.4947\tKL: 8.7599\tLL/KL: 11.7004\n",
      "====> Epoch:   80/90 (89%)\tLoss: -90.6236\tLL: 99.4135\tKL: 8.7899\tLL/KL: 11.3100\n",
      "====> Epoch:   90/105 (86%)\tLoss: -105.4323\tLL: 114.4274\tKL: 8.9951\tLL/KL: 12.7210\n",
      "====> Epoch:  100/105 (95%)\tLoss: -116.5426\tLL: 125.5945\tKL: 9.0519\tLL/KL: 13.8749\n",
      "====> Epoch:   90/105 (86%)\tLoss: -101.9060\tLL: 110.9214\tKL: 9.0154\tLL/KL: 12.3036\n",
      "====> Epoch:  100/105 (95%)\tLoss: -113.3584\tLL: 122.3581\tKL: 8.9997\tLL/KL: 13.5958\n",
      "====> Epoch:   90/105 (86%)\tLoss: -106.3199\tLL: 115.3027\tKL: 8.9827\tLL/KL: 12.8360\n",
      "====> Epoch:  100/105 (95%)\tLoss: -117.6022\tLL: 126.6422\tKL: 9.0400\tLL/KL: 14.0091\n",
      "====> Epoch:   90/105 (86%)\tLoss: -103.8851\tLL: 112.9055\tKL: 9.0204\tLL/KL: 12.5167\n",
      "====> Epoch:  100/105 (95%)\tLoss: -115.1027\tLL: 124.0867\tKL: 8.9841\tLL/KL: 13.8119\n",
      "====> Epoch:  110/120 (92%)\tLoss: -126.2498\tLL: 135.2563\tKL: 9.0065\tLL/KL: 15.0177\n",
      "====> Epoch:  110/120 (92%)\tLoss: -123.0645\tLL: 132.0876\tKL: 9.0231\tLL/KL: 14.6389\n",
      "====> Epoch:  110/120 (92%)\tLoss: -127.3391\tLL: 136.3474\tKL: 9.0083\tLL/KL: 15.1358\n",
      "====> Epoch:  110/120 (92%)\tLoss: -124.6847\tLL: 133.7464\tKL: 9.0617\tLL/KL: 14.7596\n",
      "====> Epoch:  120/135 (89%)\tLoss: -135.1916\tLL: 144.3074\tKL: 9.1158\tLL/KL: 15.8305\n",
      "====> Epoch:  130/135 (96%)\tLoss: -144.2700\tLL: 153.4772\tKL: 9.2072\tLL/KL: 16.6692\n",
      "====> Epoch:  120/135 (89%)\tLoss: -132.0226\tLL: 141.1514\tKL: 9.1288\tLL/KL: 15.4621\n",
      "====> Epoch:  130/135 (96%)\tLoss: -141.4229\tLL: 150.6078\tKL: 9.1850\tLL/KL: 16.3972\n",
      "====> Epoch:  120/135 (89%)\tLoss: -136.1297\tLL: 145.2284\tKL: 9.0987\tLL/KL: 15.9614\n",
      "====> Epoch:  130/135 (96%)\tLoss: -145.7343\tLL: 154.9386\tKL: 9.2043\tLL/KL: 16.8334\n",
      "====> Epoch:  120/135 (89%)\tLoss: -133.7465\tLL: 142.8869\tKL: 9.1404\tLL/KL: 15.6324\n",
      "====> Epoch:  130/135 (96%)\tLoss: -142.3875\tLL: 151.5867\tKL: 9.1993\tLL/KL: 16.4781\n",
      "====> Epoch:  140/150 (93%)\tLoss: -153.1416\tLL: 162.4122\tKL: 9.2706\tLL/KL: 17.5190\n",
      "====> Epoch:  140/150 (93%)\tLoss: -149.9079\tLL: 159.1467\tKL: 9.2387\tLL/KL: 17.2260\n",
      "====> Epoch:  140/150 (93%)\tLoss: -153.1653\tLL: 162.5289\tKL: 9.3636\tLL/KL: 17.3576\n",
      "====> Epoch:  140/150 (93%)\tLoss: -151.4665\tLL: 160.7416\tKL: 9.2751\tLL/KL: 17.3305\n"
     ]
    }
   ],
   "source": [
    "# Initialise paramters\n",
    "init_params = model.state_dict()\n",
    "\n",
    "# Loop over training rounds and clients\n",
    "for round_i in range(N_ROUNDS):\n",
    "    for client_dataset, client_model in zip(federated_dataset, models):\n",
    "        # Load client data in the form of a tensor\n",
    "        X, y = get_data(client_dataset)\n",
    "        # X = X.to(device=device)\n",
    "        # y = y.to(device=device)\n",
    "        client_model.data = [X.view(-1, N_FEATURES)]  # Set data attribute in client's model (list wraps the number of channels)\n",
    "\n",
    "        # Load client's model parameters and train\n",
    "        client_model.load_state_dict(init_params)\n",
    "        client_model.optimize(epochs=N_EPOCHS, data=client_model.data)\n",
    "        \n",
    "    # Aggregate models using federated averaging\n",
    "    trained_model = federated_averaging(models, n_obs_per_client)\n",
    "    init_params = trained_model.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Visualise results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "badda3f1d1321150ebb1865afb1bcc449740e2ccf220bb3debb2fa46dbffb0c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
